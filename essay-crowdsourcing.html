<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Crowdsourcing, Classification, and Research Design</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="assets/css/style.css" />
</head>
<body>
<header class="site-header">
  <div class="container nav-bar">
    <div class="logo">Shiqi Ge</div>
    <nav class="nav-links">
      <a href="index.html">Home</a>
      <a href="projects.html">Portfolio</a>
      <a href="essays.html">Essays</a>
      <a href="about.html">About</a>
      <a href="mailto:your-email@example.com">Contact</a>
    </nav>
  </div>
</header>

<main class="section essay-main">
  <div class="container essay-container">
    <header class="essay-header">
      <p class="essay-label">Essay</p>
      <h1>Crowdsourcing, Classification, and Research Design</h1>
      <p class="essay-meta">
        Course: Digital Humanities · Word count: 2095<br />
        Author: Shiqi Ge
      </p>
    </header>

    <!-- 顶部插图占位符：整篇文章的主题配图 -->
    
    <figure class="essay-figure essay-figure-cover">
      <img src="assets/img/Essay3-pic1.png" alt="Profile page screenshot from platform Zooniverse" />
      <figcaption>My participation during the past month</figcaption>
    </figure>
    

    <!-- 可选：文章内部导航（如果你不想要可以整段删掉） -->
    <!--
    <nav class="essay-toc">
      <h2>Contents</h2>
      <ol>
        <li><a href="#intro">Confronting the materiality of AI</a></li>
        <li><a href="#invisible-labour">Invisible labour in AI systems</a></li>
        <li><a href="#bias-data-dignity">Bias, data dignity, and algorithmic harms</a></li>
        <li><a href="#swartz">Aaron Swartz and knowledge infrastructures</a></li>
        <li><a href="#parallels">Parallels between AI and academic publishing</a></li>
        <li><a href="#dh-practice">Digital humanities and responsible practice</a></li>
        <li><a href="#conclusion">Conclusion: towards a more equitable knowledge landscape</a></li>
      </ol>
    </nav>
    -->

    <article class="essay-body">

      <h2 id="process">The Process</h2>
      
      <p>
      When I first browsed Zooniverse, I noticed most of the featured projects were related to natural sciences, 
        such as wildlife images and astronomical data. I was initially hesitant to engage with these projects, 
        as I felt I lacked some necessary background knowledge. Thus I began with Transcribe 2026, which 
        consisted of two tasks: transcribing whole texts and identify names from scanned documents.
      </p>
      
      <p>
      It resembled what people typically associate with crowdsourcing projects, such as CAPTCHA. Working on it 
        was quite relaxing at first as typing letters demanded little cognitive effort. However, boredom soon set 
        in because I spent much time typing and double-checking to ensure accuracy, yet it didn’t reward me with 
        a sense of achievement proportionate to the effort invested. Consequently, I turned to another project, 
        <em>Sovraimpressioni</em>, which aimed to classify photographs by General Cesare Lomaglio.
      </p>

      <figure class="essay-figure">
        <img src="assets/img/Essay3-pic2.png" alt="Screenshot of transcribing a page of scanned document" />
        <figcaption>
          Some texts may not be very clear but can be guessed from its context
        </figcaption>
      </figure>
      
      <p>
      This more complex task required participants to choose from 4 catagory labels for each photo, including living beings, 
        environment, buildings, and vehicles, followed by 4 additional questions regarding identifiable faces, handwritten 
        notes, and the determination of location and time. Although each item took less time than the transcription task, 
        the cognitive demands were obviously higher. Many photographs contained limited contextual cues, such as portraits 
        against blank walls, partial rooftops, or small interior corners. I frequently faced uncertainty when distinguishing 
        between categories such as urban, rural, or other, as well as among different building types. Between guessing and 
        giving up, I decided to experiment with consulting ChatGPT and assess whether its suggestions could be reasonably applied.
      </p>

      <figure class="essay-figure">
        <img src="assets/img/Essay3-pic3.png" alt="An indoor photograph with minimal contextual cues" />
        <figcaption>
          An indoor environment almost impossible to classify the building type
        </figcaption>
      </figure>
      
      <p>
      Most photos were difficult to determine the location and period, as they lacked obvious landmark or time features. 
        I would also click “Done & Talk” to view comments. Some participants would still take a guess from their personal 
        experience, even if they were not sure. However, I’m not familiar with Italian history and landscape, so I simply 
        presented negative answer to most subjects. What’s more, when confronted with images that were almost impossible to 
        recognize the elements, such as wildlife photographs in another project Cameras for Conservation where only a limited 
        fragment of an animal was visible, I sometimes refreshed the page to avoid being forced to classify the photo.
      </p>
      
      <figure class="essay-figure">
        <img src="assets/img/Essay3-pic4.png" alt="Screenshots of comments page where participants told the time by costumes" />
        <figcaption>
          Participants usually infer the historical period based on the costumes.
        </figcaption>
      </figure>
      
      <figure class="essay-figure">
        <img src="assets/img/Essay3-pic5.png" alt="The animal’s fur partially obscured the lens, making species identification difficult" />
        <figcaption>
          Some photos only captured a limited, blurred fragment of an animal
        </figcaption>
      </figure>
      
   

      
      <h2 id="implications">Implications of My Contribution</h2>
      
      <p>
      At first glance, transcription and image classification appear to be minor and trivial work. However, their significance emerges 
        when situated within the broader transformation enacted by digital humanities projects.
      </p>
      
      <h3>Archive as database for searching and machine learning</h3>
      
      <p>
      Through transcription and annotation, archival artefacts are transformed into structured, machine-readable data. Handwritten fragments 
        become searchable text; photographs become categorised entries. Once rendered searchable and filterable, the archive no longer 
        functions solely as a static repository but as a dynamic database that enables large-scale retrieval, comparison, and pattern detection.
      </p>
      
      <p>
      This restructuring alters how knowledge circulates. Structured datasets move more easily across disciplinary boundaries and 
        become accessible not only to specialists trained in archival reading but also to researchers in adjacent fields and non-academic 
        audiences. In this sense, digitisation does not merely preserve historical materials; it reorganises the epistemic infrastructure 
        through which they can be queried and mobilised.
      </p>
      
      <p>
      At the same time, such structured annotations contribute to a broader technological ecology. Contemporary machine learning 
        systems depend on vast quantities of human-labelled data. The categorical distinctions applied in archival annotation—such 
        as identifying faces or distinguishing types of subjects—gradually accumulate into the semantic boundaries that algorithms 
        later learn to recognise. Automated perception is therefore grounded in distributed human judgement. My individual contribution 
        may be modest, yet it participates in this larger transformation from archival interpretation to computational capacity.
      </p>
      
      <h3>Tagging on identifiable faces</h3>
      
      <h3>Socio-Technical and Ethical Implications</h3>
      
      <p>
      However, reflecting on my contribution also raises ethical questions about labour, ownership, and recognition within crowdsourced 
        research. Crowdsourcing distributes intellectual work across many contributors, yet these contributors often occupy an ambiguous 
        position. They are neither formal authors nor traditional research participants; rather, they function as infrastructural labour 
        whose contributions enable knowledge production but remain largely invisible in the final output. As Marinova (2016) argues, by 
        relying on commercial crowdsourcing platforms, researchers risk reinforcing a legal and economic model grounded in precarious labor, 
        asymmetrical power relations, and the absence of worker protections.
      </p>
      
      <p>
      This raises questions of attribution and academic recognition. While the aggregated dataset may support scholarly publications or 
        institutional projects, individual contributors are rarely acknowledged beyond collective mention. The model depends on fragmenting 
        labour into micro-tasks, which increases efficiency but diffuses responsibility and obscures authorship.
      </p>
      
      <p>
      My decision to occasionally consult ChatGPT further complicated the system. Crowdsourcing is premised on distributed human judgement, 
        where independent participants contribute individual interpretations. By introducing an external AI system into the process, I 
        effectively hybridised that judgement. Although the platform does not explicitly prohibit such practices, the use of generative AI 
        raises questions about epistemic contamination: does the aggregation of responses still represent collective human assessment, or a 
        mixture of human and algorithmic inference?
      </p>
      
      <p>
      Additionally, crowdsourced work exists within broader political and economic structures. Online contributors frequently operate as 
        informal digital workers in precarious conditions, particularly across Global North–Global South inequalities. Even when compensation 
        is provided, payment structures may reflect global wage asymmetries (Du et al., 2024). Participating in such a system, even as a 
        volunteer or paid contributor, means becoming embedded within a wider economy of platform-mediated labour.
      </p>
      
      <p>
      Recognising these dimensions does not invalidate the value of crowdsourcing. Rather, it highlights that my contribution was not 
        neutral or purely technical. It was situated within a socio-technical system that shapes not only data, but also labour relations, 
        power structures, and the distribution of epistemic credit.
      </p>

      <!-- 插图占位符：数字人文实践 / 课堂或作品截图 -->
      <!--
      <figure class="essay-figure">
        <img src="assets/img/essays/dh-practice.jpg" alt="Screenshot of a digital humanities project interface" />
        <figcaption>Figure 4. Situating digital humanities practice within broader infrastructures and ethics.</figcaption>
      </figure>
      -->

      <h2 id="conclusion">Conclusion: towards a more equitable knowledge landscape</h2>
      <p>
        From AI supply chains to academic publishing, we encounter a tightly interconnected landscape of knowledge
        production, which offers extraordinary possibilities while reproducing deep inequalities. The task of digital
        humanists is not only to create but to critique; not only to innovate but to imagine alternatives. Aaron Swartz may
        not have lived to see the transformations he hoped for, but his legacy endures as a reminder that knowledge can and
        should be a public good. Through my own small contributions to openness, reflexivity, and digital ethics, I aim to
        contribute, in small ways, to a more equitable knowledge landscape.
      </p>
      <h2>References</h2>
      <ul class="reference-list">
        <li>
          Bender, E., Gebru, T., McMillan-Major, A. and Mitchell, M. (2021) 
          'On the dangers of stochastic parrots: Can language models be too big?'.
          <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT '21). </em>
          Association for Computing Machinery, New York, NY, USA, pp. 610–623. 
          https://doi.org/10.1145/3442188.3445922.
        </li>
        <li>
          Buolamwini, J. (2016) 
          'How I’m fighting bias in algorithms', TED Talk. 
          Available at: https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms 
          (Accessed: 27 November 2025).
        </li>
        <li>
          Crawford, K. and Joler, V. (2018) 
          <em>Anatomy of an AI System: The Amazon Echo as an anatomical map of human labor, data and planetary resources.</em> 
          Available at: https://anatomyof.ai 
          (Accessed: 27 November 2025).
        </li>
        <li>
          Knappenberger, B. (2014) 
          <em>The Internet’s Own Boy: The Story of Aaron Swartz</em> [Documentary film]. 
          Available at: https://www.youtube.com/watch?v=9vz06QO3UkQ 
          (Accessed: 26 November 2025).
        </li>
        <li>
          Lanier, J. (2023) 
          ‘There Is No A.I.’, <em>The New Yorker</em>, 16 April. 
          Available at: https://www.newyorker.com/science/annals-of-artificial-intelligence/there-is-no-ai 
          (Accessed: 27 November 2025).
        </li>
        <li>
          Lessig, L. (2001) 
          <em>The Future of Ideas: The Fate of the Commons in a Connected World.</em> 
          New York: Random House.
        </li>
        <li>
          Noble, S.U. (2014) 
          'How biased are our algorithms?'. TEDxUIUC [Video]. 
          Available at: https://scalar.usc.edu/works/intro-to-dh-hs3393/how-biased-are-our-algorithms--safiya-umoja-noble--tedxuiuc 
          (Accessed: 27 November 2025).
        </li>
      </ul>
    </article>
  </div>
</main>


<footer class="site-footer">
  <div class="container">
    <p>© <span id="year"></span> Shiqi Ge · Digital Arts &amp; Humanities</p>
  </div>
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</footer>
</body>
</html>
